{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from pathlib import Path\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os # For path.basename and cpu_count\n",
    "import tensorflow as tf # Ensure tf is imported for type hints and operations\n",
    "from tensorflow.keras.models import load_model # For loading model in worker\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm # For progress bar"
   ],
   "id": "46d230f9698cf0de",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T00:33:11.640904Z",
     "start_time": "2025-05-15T00:33:11.638533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def combined_mse_cosine_loss(y_true, y_pred):\n",
    "    mse = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "    y_true_norm = tf.nn.l2_normalize(y_true, axis=1)\n",
    "    y_pred_norm = tf.nn.l2_normalize(y_pred, axis=1)\n",
    "    cosine_loss = 1 - tf.reduce_mean(tf.reduce_sum(y_true_norm * y_pred_norm, axis=1))\n",
    "    return mse + 0.3 * cosine_loss"
   ],
   "id": "22c7d27ff892b3c7",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T00:33:11.698853Z",
     "start_time": "2025-05-15T00:33:11.696021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_path = \"models/custom_cnn.keras\"\n",
    "new_spectrogram_path = \"spectrogram/test_data/000002_spectrogram_win_length=2048_hop_length=512_n_fft=2048.png\"\n",
    "FEATURE_NAMES = [\n",
    "    \"acousticness\", \"instrumentalness\", \"liveness\", \"speechiness\",\n",
    "    \"danceability\", \"energy\", \"tempo\", \"valence\"\n",
    "]\n",
    "\n",
    "if len(FEATURE_NAMES) != 8:\n",
    "    raise ValueError(\"FEATURE_NAMES list must contain exactly 8 names.\")"
   ],
   "id": "c0175dad3af66b3b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-15T00:33:13.224156Z",
     "start_time": "2025-05-15T00:33:11.746528Z"
    }
   },
   "source": [
    "# 1. Load the trained model with the custom loss function\n",
    "print(f\"Loading model from: {model_path}\")\n",
    "# Ensure model_path is a string or Path object correctly pointing to your model\n",
    "# from pathlib import Path # if you want to use Path objects\n",
    "# model_path_obj = Path(model_path)\n",
    "# if not model_path_obj.exists():\n",
    "#     raise FileNotFoundError(f\"Model file not found at {model_path}\")\n",
    "\n",
    "try:\n",
    "    # It's good practice to clear session in notebooks if re-running model related code\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    model = load_model(\n",
    "        model_path,\n",
    "        custom_objects={'combined_mse_cosine_loss': combined_mse_cosine_loss}\n",
    "    )\n",
    "    print(\"Model loaded successfully.\")\n",
    "    model.summary()  # Optional: print model summary\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    # In a notebook, you might want to raise the exception to stop execution\n",
    "    raise"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: models/custom_cnn.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1747269192.436242  610385 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5564 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001B[38;5;33mConv2D\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m326\u001B[0m, \u001B[38;5;34m793\u001B[0m, \u001B[38;5;34m32\u001B[0m)   │           \u001B[38;5;34m896\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001B[38;5;33mMaxPooling2D\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m163\u001B[0m, \u001B[38;5;34m396\u001B[0m, \u001B[38;5;34m32\u001B[0m)   │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m161\u001B[0m, \u001B[38;5;34m394\u001B[0m, \u001B[38;5;34m64\u001B[0m)   │        \u001B[38;5;34m18,496\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001B[38;5;33mMaxPooling2D\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m80\u001B[0m, \u001B[38;5;34m197\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001B[38;5;33mConv2D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m78\u001B[0m, \u001B[38;5;34m195\u001B[0m, \u001B[38;5;34m128\u001B[0m)   │        \u001B[38;5;34m73,856\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "│ (\u001B[38;5;33mGlobalAveragePooling2D\u001B[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m)             │         \u001B[38;5;34m8,256\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m)              │           \u001B[38;5;34m520\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">326</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">793</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">163</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">396</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">161</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">394</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">197</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">78</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m306,074\u001B[0m (1.17 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">306,074</span> (1.17 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m102,024\u001B[0m (398.53 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">102,024</span> (398.53 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Optimizer params: \u001B[0m\u001B[38;5;34m204,050\u001B[0m (797.07 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">204,050</span> (797.07 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T00:33:13.280436Z",
     "start_time": "2025-05-15T00:33:13.277994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    image = tf.image.resize(image, (int(984 / 3), int(2385 / 3)))\n",
    "    image = tf.keras.applications.resnet50.preprocess_input(image)\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "    return image"
   ],
   "id": "a76a34562ec3c122",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T00:33:35.440456Z",
     "start_time": "2025-05-15T00:33:13.332511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load image\n",
    "image = load_image(new_spectrogram_path)\n",
    "\n",
    "# Make predictions\n",
    "print(\"\\nMaking prediction...\")\n",
    "try:\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        predictions = model.predict(image)\n",
    "\n",
    "    # predictions will be a numpy array like [[feat1, feat2, ..., feat8]]\n",
    "    predicted_features = predictions[0]\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"\\nPredicted Audio Features for {new_spectrogram_path}:\")\n",
    "    if len(predicted_features) == len(FEATURE_NAMES):\n",
    "        for name, value in zip(FEATURE_NAMES, predicted_features):\n",
    "            print(f\"- {name}: {value:.4f}\")\n",
    "    else:\n",
    "        print(\"Warning: Number of predicted features does not match FEATURE_NAMES length.\")\n",
    "        print(\"Raw predictions:\", predicted_features)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during prediction: {e}\")\n",
    "    # In a notebook, you might want to raise the exception\n",
    "    raise"
   ],
   "id": "26daa55efdf28eb4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Making prediction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1747269193.483968  610528 service.cc:152] XLA service 0x7f52e4006a50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1747269193.483998  610528 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3070, Compute Capability 8.6\n",
      "2025-05-14 20:33:13.490356: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1747269193.508983  610528 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-05-14 20:33:14.687749: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng11{k2=2,k3=0} for conv %cudnn-conv-bias-activation.9 = (f32[1,32,326,793]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,3,328,795]{3,2,1,0} %bitcast.204, f32[32,3,3,3]{3,2,1,0} %bitcast.211, f32[32]{0} %bitcast.213), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/ubuntu/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-05-14 20:33:15.497650: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.815327353s\n",
      "Trying algorithm eng11{k2=2,k3=0} for conv %cudnn-conv-bias-activation.9 = (f32[1,32,326,793]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,3,328,795]{3,2,1,0} %bitcast.204, f32[32,3,3,3]{3,2,1,0} %bitcast.211, f32[32]{0} %bitcast.213), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/ubuntu/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-05-14 20:33:16.511069: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng33{k2=2,k6=0,k13=1,k14=0,k22=1} for conv %cudnn-conv-bias-activation.9 = (f32[1,32,326,793]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,3,328,795]{3,2,1,0} %bitcast.204, f32[32,3,3,3]{3,2,1,0} %bitcast.211, f32[32]{0} %bitcast.213), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/ubuntu/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-05-14 20:33:23.696946: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 8.190982141s\n",
      "Trying algorithm eng33{k2=2,k6=0,k13=1,k14=0,k22=1} for conv %cudnn-conv-bias-activation.9 = (f32[1,32,326,793]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,3,328,795]{3,2,1,0} %bitcast.204, f32[32,3,3,3]{3,2,1,0} %bitcast.211, f32[32]{0} %bitcast.213), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/ubuntu/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-05-14 20:33:24.720562: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng0{} for conv %cudnn-conv-bias-activation.9 = (f32[1,32,326,793]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,3,328,795]{3,2,1,0} %bitcast.204, f32[32,3,3,3]{3,2,1,0} %bitcast.211, f32[32]{0} %bitcast.213), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/ubuntu/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-05-14 20:33:25.378599: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.663063542s\n",
      "Trying algorithm eng0{} for conv %cudnn-conv-bias-activation.9 = (f32[1,32,326,793]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,3,328,795]{3,2,1,0} %bitcast.204, f32[32,3,3,3]{3,2,1,0} %bitcast.211, f32[32]{0} %bitcast.213), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/home/ubuntu/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-05-14 20:33:26.455309: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng33{k2=2,k6=0,k13=1,k14=0,k22=1} for conv %cudnn-conv-bias-activation.10 = (f32[1,64,161,394]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,32,163,396]{3,2,1,0} %bitcast.220, f32[64,32,3,3]{3,2,1,0} %bitcast.227, f32[64]{0} %bitcast.229), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/ubuntu/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-05-14 20:33:27.234490: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.787406601s\n",
      "Trying algorithm eng33{k2=2,k6=0,k13=1,k14=0,k22=1} for conv %cudnn-conv-bias-activation.10 = (f32[1,64,161,394]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,32,163,396]{3,2,1,0} %bitcast.220, f32[64,32,3,3]{3,2,1,0} %bitcast.227, f32[64]{0} %bitcast.229), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/ubuntu/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-05-14 20:33:28.311343: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng33{k2=2,k6=0,k13=2,k14=0,k22=2} for conv %cudnn-conv-bias-activation.10 = (f32[1,64,161,394]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,32,163,396]{3,2,1,0} %bitcast.220, f32[64,32,3,3]{3,2,1,0} %bitcast.227, f32[64]{0} %bitcast.229), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/ubuntu/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-05-14 20:33:28.715007: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.404935591s\n",
      "Trying algorithm eng33{k2=2,k6=0,k13=2,k14=0,k22=2} for conv %cudnn-conv-bias-activation.10 = (f32[1,64,161,394]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,32,163,396]{3,2,1,0} %bitcast.220, f32[64,32,3,3]{3,2,1,0} %bitcast.227, f32[64]{0} %bitcast.229), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/ubuntu/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-05-14 20:33:30.281764: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng0{} for conv %cudnn-conv-bias-activation.10 = (f32[1,64,161,394]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,32,163,396]{3,2,1,0} %bitcast.220, f32[64,32,3,3]{3,2,1,0} %bitcast.227, f32[64]{0} %bitcast.229), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/ubuntu/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-05-14 20:33:33.387118: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 4.112080371s\n",
      "Trying algorithm eng0{} for conv %cudnn-conv-bias-activation.10 = (f32[1,64,161,394]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,32,163,396]{3,2,1,0} %bitcast.220, f32[64,32,3,3]{3,2,1,0} %bitcast.227, f32[64]{0} %bitcast.229), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/home/ubuntu/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-05-14 20:33:34.463041: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng11{k2=2,k3=0} for conv %cudnn-conv-bias-activation.11 = (f32[1,128,78,195]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,64,80,197]{3,2,1,0} %bitcast.235, f32[128,64,3,3]{3,2,1,0} %bitcast.242, f32[128]{0} %bitcast.244), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/ubuntu/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n",
      "2025-05-14 20:33:34.828280: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.366282809s\n",
      "Trying algorithm eng11{k2=2,k3=0} for conv %cudnn-conv-bias-activation.11 = (f32[1,128,78,195]{3,2,1,0}, u8[0]{0}) custom-call(f32[1,64,80,197]{3,2,1,0} %bitcast.235, f32[128,64,3,3]{3,2,1,0} %bitcast.242, f32[128]{0} %bitcast.244), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_2_1/convolution\" source_file=\"/home/ubuntu/.local/lib/python3.12/site-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false} is taking a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m22s\u001B[0m 22s/step\n",
      "\n",
      "Predicted Audio Features for spectrogram/test_data/000002_spectrogram_win_length=2048_hop_length=512_n_fft=2048.png:\n",
      "- acousticness: 0.4835\n",
      "- instrumentalness: 0.5398\n",
      "- liveness: 0.5232\n",
      "- speechiness: 0.3900\n",
      "- danceability: 0.1837\n",
      "- energy: 0.2060\n",
      "- tempo: 0.4148\n",
      "- valence: 0.5676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1747269215.307757  610528 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T00:38:11.788422Z",
     "start_time": "2025-05-15T00:38:11.783817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Configuration for the song database ---\n",
    "DATABASE_SPECTROGRAM_DIR = Path(\"spectrogram/fma_large/\") # Directory of spectrograms\n",
    "CSV_FEATURES_PATH = Path(\"data/echonest_norm.csv\") # Path to your CSV with pre-computed features\n",
    "NUM_SIMILAR_SONGS_TO_FIND = 5\n",
    "\n",
    "\n",
    "# --- Helper Functions ---\n",
    "# parse_track_id_from_filename is no longer needed if we only use the CSV\n",
    "\n",
    "def build_feature_database_from_csv(csv_file_path, feature_names_ordered_list):\n",
    "    \"\"\"\n",
    "    Builds a feature database by reading pre-computed features directly from a CSV file.\n",
    "    Concise version with fewer sanity checks.\n",
    "    \"\"\"\n",
    "    feature_db = []\n",
    "\n",
    "    try:\n",
    "        features_df = pd.read_csv(csv_file_path)\n",
    "        # Assume the first column is the track_id, rename if not already 'track_id'\n",
    "        id_column_name = features_df.columns[0]\n",
    "        if id_column_name != 'track_id':\n",
    "            features_df.rename(columns={id_column_name: 'track_id'}, inplace=True)\n",
    "        # features_df.set_index('track_id', inplace=True) # No longer setting index, will iterate rows\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or processing CSV file {csv_file_path}: {e}\")\n",
    "        return feature_db # Return empty if CSV loading fails\n",
    "\n",
    "    print(f\"Building database directly from CSV: {csv_file_path}\")\n",
    "    # Iterate over rows of the DataFrame\n",
    "    for index, row in tqdm(features_df.iterrows(), total=features_df.shape[0], desc=\"Building database from CSV rows\"):\n",
    "        track_id = row['track_id'] # Get track_id from the row\n",
    "        try:\n",
    "            # Select features from the row IN THE ORDER SPECIFIED BY feature_names_ordered_list\n",
    "            feature_vector = row[feature_names_ordered_list].values.astype(np.float32)\n",
    "            # Assuming feature_vector will have correct length if all columns in feature_names_ordered_list exist\n",
    "\n",
    "            # Store the track_id (or other identifier from CSV) and its features\n",
    "            # Using track_id as the identifier now, not a file path.\n",
    "            feature_db.append((track_id, feature_vector))\n",
    "        except (KeyError, ValueError, TypeError) as e:\n",
    "            print(f\"Skipping track_id {track_id} due to error: {e}\")\n",
    "            # Skip this track if features can't be correctly extracted or cast\n",
    "            continue\n",
    "\n",
    "    print(f\"Feature database built with {len(feature_db)} songs from CSV.\")\n",
    "    return feature_db\n",
    "\n",
    "def euclidean_distance(vec1, vec2):\n",
    "    \"\"\"Computes the Euclidean distance between two vectors.\"\"\"\n",
    "    return np.sqrt(np.sum((np.array(vec1) - np.array(vec2))**2))\n",
    "\n",
    "def find_k_nearest_neighbors(input_song_features, db_features_list, k=5):\n",
    "    \"\"\"\n",
    "    Finds the k most similar songs from the db_features_list to the input_song_features.\n",
    "    \"\"\"\n",
    "    if not db_features_list: # Keep this check as it's fundamental\n",
    "        return []\n",
    "    distances = []\n",
    "    # song_id here will now be the track_id from the CSV\n",
    "    for song_id, feature_vec in tqdm(db_features_list, desc=f\"Finding {k} nearest neighbors\"):\n",
    "        dist = euclidean_distance(input_song_features, feature_vec)\n",
    "        distances.append((song_id, dist))\n",
    "    distances.sort(key=lambda item: item[1])\n",
    "    return distances[:k]"
   ],
   "id": "7b510586703bb8fb",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T00:38:14.076540Z",
     "start_time": "2025-05-15T00:38:12.430010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Main Logic for Similarity Search ---\n",
    "\n",
    "# The following variables are assumed to be defined in your notebook from previous cells:\n",
    "# - predicted_features: Numpy array of features for the INPUT song (from Keras model).\n",
    "# - new_spectrogram_path: Path (string or Path object) to the INPUT song's spectrogram (used for display).\n",
    "# - FEATURE_NAMES: List of 8 feature names in the order your Keras model outputs them.\n",
    "#   (This is now also used by build_feature_database_from_csv)\n",
    "\n",
    "# The Keras 'model' object and 'model_path' string are no longer directly used by\n",
    "# this specific cell's database building logic, but 'model' was used to get 'predicted_features'.\n",
    "\n",
    "# Assuming FEATURE_NAMES is correctly defined and available from previous cells.\n",
    "song_feature_database = build_feature_database_from_csv(\n",
    "    CSV_FEATURES_PATH,\n",
    "    FEATURE_NAMES # Pass the ordered list of feature names\n",
    ")"
   ],
   "id": "88b11be4dd1e2540",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building database directly from CSV: data/echonest_norm.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building database from CSV rows: 100%|██████████| 13131/13131 [00:01<00:00, 8079.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature database built with 13131 songs from CSV.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T00:39:25.647842Z",
     "start_time": "2025-05-15T00:39:25.601766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if not song_feature_database:\n",
    "    print(\"Cannot perform similarity search because the feature database is empty or could not be built from CSV.\")\n",
    "else:\n",
    "    display_path_for_input_song = str(new_spectrogram_path) # Used for display only\n",
    "\n",
    "    print(f\"\\nFinding {NUM_SIMILAR_SONGS_TO_FIND} songs most similar to '{display_path_for_input_song}'...\")\n",
    "    # The note about matching spectrogram filename is less relevant now, as matching is based on CSV content.\n",
    "    # However, if your input song's track_id (derived from its filename) happens to be in the CSV,\n",
    "    # it might still match itself if its features are identical.\n",
    "    print(\"Note: The input song itself may appear in results if its features are identical to an entry in the CSV.\")\n",
    "\n",
    "    similar_songs = find_k_nearest_neighbors(\n",
    "        predicted_features,\n",
    "        song_feature_database,\n",
    "        k=NUM_SIMILAR_SONGS_TO_FIND\n",
    "    )\n",
    "\n",
    "    if similar_songs:\n",
    "        print(f\"\\nTop {len(similar_songs)} similar songs (Track IDs from CSV):\")\n",
    "        for i, (song_id, dist) in enumerate(similar_songs): # song_id is now the track_id\n",
    "            print(f\"{i+1}. Track ID: {int(song_id)} (Distance: {dist:.4f})\")\n",
    "    else:\n",
    "        print(\"No similar songs found (this usually means the database was empty or no matches were found).\")\n",
    "\n"
   ],
   "id": "75ef59d0dae1e069",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding 5 songs most similar to 'spectrogram/test_data/000002_spectrogram_win_length=2048_hop_length=512_n_fft=2048.png'...\n",
      "Note: The input song itself may appear in results if its features are identical to an entry in the CSV.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding 5 nearest neighbors: 100%|██████████| 13131/13131 [00:00<00:00, 347272.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 similar songs (Track IDs from CSV):\n",
      "1. Track ID: 9546 (Distance: 0.4618)\n",
      "2. Track ID: 16232 (Distance: 0.4887)\n",
      "3. Track ID: 44249 (Distance: 0.4903)\n",
      "4. Track ID: 32094 (Distance: 0.4959)\n",
      "5. Track ID: 45462 (Distance: 0.5114)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3bae8da9a8f99ad0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
